# -*- coding: utf-8 -*-
"""fuzzy.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TG4jgZggi6t33sIIv-xUbS-Nfzt_GJ7P
"""

# ===========================================
# CAMPUS ENTITY FUZZY SEARCH + DASHBOARD + TIMELINE
# ===========================================

!pip install rapidfuzz matplotlib

import sqlite3
import pandas as pd
import matplotlib.pyplot as plt
from rapidfuzz import process, fuzz

# 1Ô∏è‚É£ CONNECT TO DATABASE
# -------------------------------------------
db_path = "campus_er.db"
conn = sqlite3.connect(db_path)

# 2Ô∏è‚É£ FUZZY SEARCH FUNCTION
# -------------------------------------------
def fuzzy_search(query, top_n=5, min_score=60):
    df_entities = pd.read_sql_query("SELECT * FROM entities;", conn)
    df_entities['combined'] = df_entities['name'].fillna('') + " | " + df_entities['email'].fillna('')
    results = process.extract(query, df_entities['combined'], scorer=fuzz.token_set_ratio, limit=top_n)

    matches = []
    for match_text, score, idx in results:
        if score >= min_score:
            row = df_entities.iloc[idx]
            matches.append({
                "entity_id": row['entity_id'],
                "name": row['name'],
                "email": row['email'],
                "role": row['role'],
                "similarity": score
            })
    return pd.DataFrame(matches)

# 3Ô∏è‚É£ FETCH RELATED DATA
# -------------------------------------------
def fetch_related_data(entity_id):
    print(f"\nüìò ENTITY PROFILE for {entity_id}")

    # ENTITY INFO
    entity = pd.read_sql_query(f"SELECT * FROM entities WHERE entity_id='{entity_id}';", conn)
    display(entity)

    # EVENTS
    events = pd.read_sql_query(f"SELECT * FROM events WHERE entity_id='{entity_id}';", conn)

    # NOTES
    notes = pd.read_sql_query(f"SELECT * FROM notes WHERE entity_id='{entity_id}';", conn)

    # FACE EMBEDDINGS
    faces = pd.read_sql_query(f"SELECT * FROM face_embeddings WHERE entity_id='{entity_id}';", conn)

    # TRANSITIONS (GLOBAL)
    transitions = pd.read_sql_query("SELECT * FROM transitions ORDER BY count DESC LIMIT 10;", conn)

    # --- Display Summary Dashboard ---
    print("\nüìä DASHBOARD SUMMARY")
    print(f"Events logged: {len(events)}")
    print(f"Notes available: {len(notes)}")
    print(f"Face embeddings: {len(faces)}")

    if not events.empty:
        print(f"First seen: {events['timestamp'].min()}")
        print(f"Last seen: {events['timestamp'].max()}")
    else:
        print("No movement records available.")

    # --- Timeline Visualization ---
    if not events.empty:
        print("\nüïì TIMELINE OF MOVEMENTS")
        events_sorted = events.sort_values("timestamp")
        plt.figure(figsize=(10,4))
        plt.plot(events_sorted['timestamp'], range(len(events_sorted)), marker='o')
        plt.title(f"Movement Timeline for {entity.iloc[0]['name']}")
        plt.xlabel("Timestamp")
        plt.ylabel("Event Sequence")
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.show()
    else:
        print("No timeline data to plot.")

    # --- Detailed Views ---
    if not events.empty:
        print("\nüìç EVENTS:")
        display(events[['location', 'timestamp', 'source']])
    if not notes.empty:
        print("\nüóíÔ∏è NOTES:")
        display(notes[['timestamp', 'category', 'text']])
    if not faces.empty:
        print("\nüì∏ FACE EMBEDDINGS:")
        display(faces[['face_id', 'camera_id', 'timestamp']])

    print("\nüö∂ GLOBAL MOVEMENT PATTERNS (Top 10):")
    display(transitions[['from_loc', 'to_loc', 'count', 'prob']])

# 4Ô∏è‚É£ MAIN WORKFLOW
# -------------------------------------------
query = input("üîç Enter name or email to search: ").strip()
matches = fuzzy_search(query)

if matches.empty:
    print("‚ùå No matches found.")
else:
    print(f"\nTop matches for '{query}':")
    display(matches)

    # Automatically pick best match
    top_entity = matches.iloc[0]['entity_id']
    fetch_related_data(top_entity)

